---
title: "lab4_cappy"
format: html
editor: visual
---

What almost every R project should start with:

```{r}
setwd("<location of this github repository on your computer>")
source("src/<your_last_name.R")
```

```{r}
p_ij = intersect(which(site_i==1),which(site_j==1))/length(site_i)
# intersect is going to figure out where sites i and j share the same value and tell you where it does
# setdiff --> tells you where all the sites with differences are (opposite of intersect)
# this code doesn't actually give you what you need to do the math
length(intercept)/length(???)
```

Calculating LD

create fake data:

```{r}
site_A = c(1,0,NA,1,0,1)
site_B = c(1,NA,0,1,0,1)
site_C = c(0,1,1,NA,1,0)
```

0s mean same as reference allele

1s mean different than reference allele

```{r}
#Function to run on each row
allele_2_num = function(site,name){
  div_allele = gsub(".*:.*:([A,T,C,G]+):","",name)
  GT_row = as.numeric(site==div_allele)
  return(GT_row)
}

#Structure for whole vcf
extract_haps = function(vcf){
  haps = extract.haps(vcf)
  names = rownames(haps)
  num_mat = t(sapply(1:dim(haps)[1],function(x) allele_2_num(haps[x,],names[x])))
  rownames(num_mat) = names
  colnames(num_mat) = colnames(haps)
  return(num_mat)
}

                     #############################################
                     
# Calculating freq for sites equal to 1
  # ignoring NAs
freq_ij = function(site_i,site_j){
    n_ij = length(intersect(which(site_i==1),which(site_j==1)))
    n_sites =  length(which(!is.na(site_i)) | which (!is.na(site_j)))
    return(n_ij/n_sites)
}
```

number of sites: accounting for n/a

-   can look at sites that only contain information in both individuals

-   which(!is.na(site i) and which (!is.na(sitej)

Changing freq_GT for dif ploidy

```{r}
freq_GT = function(site,ploidy=2){
  clean_site = na.omit(site)
  total_sites = ploidy*length(site)
  p = sum(clean_site)/total_sites
  return(p)
}
```

What is the average $D_ij$ in the muc19 data?

```{r}
{r}
d_ij = function(site_i,site_j){
    p_i = freq_GT(site_i,1)
    p_j = freq_GT(site_j,1)
    p_ij = freq_ij(site_i,site_j)
    D_ij = p_ij - p_i*p_j
    return(D_ij)
}
```

Calculating r\^2

```{r}
cor_mat = cor(t(GT))
```

Calculating LD for the file

-   apply function on genotype matrix

-   apply(GT,1,function(X), freq_GT(x,1))

-   combn(1:dim(GT)\[1\],2,replacement??? order doesnt matter)

-   hard to run on large data –\> thin the data, reduce data complexity

-   plink software –\> helps with thinning the data, also more efficient than R

LD prunning data

-   drops the data thats correlated

-   go across tiny windows across the genome (window function)

-   chromosome function

-   and then a function that calls both the previous two functions

string in vcfs

-   12 : 2348786 : C : T

-   chromosome# : position : ref allele : alternate allele

special characters

-   "." –\> any character

-   "\*" –\> repeat any number of times

**homework –\>** run the plink code on the vcf and make sure it works

-   copied and made script for plink code & ran it on laptop

## LD-pruning in R (function)

```{r}
#Function to LD-prune a VCF. Makes calls to subfunctions for each chromosome, and each of those runs sub-functions on each window.
#For a variety of reasons, we drop _all_ alleles with no variation (e.g. allele frequency ==0 or 1).

ld_prune = function(vcf,window_size,cutoff=0.1){
  GT = extract_haps(vcf)
  freqs = apply(GT,1,function(x) freq_GT(x,ploidy=1))
  GT = GT[which(freqs*(1-freqs)>0),]
  chr_id = gsub(":.*:.*:.*","",rownames(GT))
  chrs = sort(unique(chr_id))
  sub_GT = lapply(chrs,function(x) ld_prune_chr(GT[chr_id==x,],window_size=window_size,cutoff=cutoff)) 
  return(sub_GT)
}

#Within each chromosome, generate windows and find only the sites to be dropped.
ld_prune_chr = function(GT,window_size,cutoff=0.1){
  pos = as.numeric(gsub(".*:([0-9]*):.*","\\1",rownames(GT)))
  breaks = unique(c(seq(from=min(pos)-1,to=max(pos),by=window_size),max(pos)))
  bins = cut(pos,breaks,right=TRUE)
  #Drop bins with 1 or fewer entries
  bad_bins = names(which(table(bins)<2))
  bins = factor(bins,exclude=bad_bins)
  drop = unlist(sapply(levels(bins),function(x) ld_prune_window(GT[which(bins==x),],cutoff=cutoff)))
  sub_GT = GT[setdiff(rownames(GT),drop),]
  return(sub_GT)
}

#Within each window, calculate correlations, keep only the first allele with high correlations
ld_prune_window = function(GT,cutoff=0.1){
  cor_mat = cor(t(GT))
  to_check = 1:dim(cor_mat)[1]
  drop = c()
  while(length(to_check)>0){
    high_cor = which(cor_mat[to_check[1],]>cutoff)
    drop = c(drop,setdiff(high_cor,to_check[1]))
    to_check = setdiff(to_check,high_cor)
  }
  if(length(drop)>0){
    return(rownames(GT)[drop])
  }
}

```

### Questions:

1.  What is the total number of SNPs that remain after you LD prune the muc19 data using a 250bp window?

    ```{r}
    setwd("/Users/caprinapugliese/Documents/School/Uconn/2024-26_Grad_School/2025-26_Year-2/popgen/labs/cappys_labs")
    source("code/lab4_src.R")

    vcf_prune_250 <- ld_prune(vcf, 250, 0.1)
    vcf_prune_500 <- ld_prune(vcf, 500, 0.1)
    # regular vcf:       24489 rows
    # pruned vcf (250):  10155 rows
    # pruned vcf (500):   9165 rows


    #chr_prune_250 <- ld_prune_chr(GT, 250, 0.1)
    #window_prune_250 <- ld_prune_window(GT, 0.1)

    ```

2.  What about a 500 bp window?

### Blackboard question:

How much smaller were your vcfs following LD-pruning? Did things change in expected ways?

24489 rows: regular vcf

10155 rows: pruned vcf (250)

9165 rows: pruned vcf (500)

Yes, as we increased the window size, more of the sites got dropped. I believe this is because it is walking across the genome in bigger chunks, and able to toss out more of the repeat information at similar sites.